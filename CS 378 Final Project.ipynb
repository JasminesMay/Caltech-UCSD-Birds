{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "    file = open(filename, \"r\") \n",
    "    image_names = file.readlines()\n",
    "    images = []\n",
    "    labels = []\n",
    "    counter = 1\n",
    "    for name in image_names:\n",
    "        label = name[:3]\n",
    "        if label <= \"001\":\n",
    "            im = Image.open(\"images/\" + name.rstrip('\\n'))\n",
    "            H, W = im.size\n",
    "            pixels = list(im.getdata())\n",
    "            image = np.array([comp for pixel in pixels for comp in pixel]).reshape(H, W, 3)\n",
    "            print(image.shape)\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "            if counter >= 2:\n",
    "                break\n",
    "            counter += 1\n",
    "            \n",
    "#     print(len(images))\n",
    "#     print(len(labels))\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load('train.txt')\n",
    "\n",
    "# print('Input shape: ' + str(image_data.shape))\n",
    "# print('Labels shape: ' + str(label_data.shape))\n",
    "\n",
    "# num_classes = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv/Relu:0\", shape=(?, ?, 20), dtype=float32)\n",
      "(500, 336, 3)\n",
      "Tensor(\"ToFloat:0\", shape=(500, 336, 3), dtype=float32)\n",
      "(415, 500, 3)\n",
      "Tensor(\"ToFloat_1:0\", shape=(415, 500, 3), dtype=float32)\n",
      "Total number of variables used  0.0 / 500000\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.placeholder(tf.float32, (None,None,3))\n",
    "net = tf.identity(inputs, name='net')\n",
    "net = tf.contrib.layers.conv2d(net, 20, 3, stride=2, activation_fn=tf.nn.relu)\n",
    "# net = tf.contrib.layers.conv2d(net, 30, 3, stride=2, activation_fn=tf.nn.relu)\n",
    "print(net)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def load(filename):\n",
    "    file = open(filename, \"r\") \n",
    "    image_names = file.readlines()\n",
    "    images = []\n",
    "    labels = []\n",
    "    counter = 1\n",
    "    for name in image_names:\n",
    "        label = name[:3]\n",
    "        if label <= \"001\":\n",
    "            im = Image.open(\"images/\" + name.rstrip('\\n'))\n",
    "            H, W = im.size\n",
    "            pixels = list(im.getdata())\n",
    "            image = np.array([comp for pixel in pixels for comp in pixel]).reshape(H, W, 3)\n",
    "            print(image.shape)\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "            \n",
    "            t_image = tf.convert_to_tensor(image)\n",
    "            t_image = tf.to_float(image)\n",
    "#             net = tf.identity(t_image, name='net')\n",
    "#             net = tf.contrib.layers.conv2d(net, 20, 3, stride=2, activation_fn=tf.nn.relu)\n",
    "#             print(net.shape)\n",
    "            \n",
    "            \n",
    "            if counter >= 2:\n",
    "                break\n",
    "            counter += 1\n",
    "            \n",
    "            \n",
    "#     print(len(images))\n",
    "#     print(len(labels))\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load('train.txt')\n",
    "\n",
    "# print('Input shape: ' + str(image_data.shape))\n",
    "# print('Labels shape: ' + str(label_data.shape))\n",
    "\n",
    "# num_classes = 200\n",
    "\n",
    "print( \"Total number of variables used \", np.sum([v.get_shape().num_elements() for v in tf.trainable_variables()]), '/', 500000 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 500, 336, 3)\n",
      "Tensor(\"image_filters/conv2/Relu:0\", shape=(1, 125, 84, 3), dtype=float32)\n",
      "(1, 415, 500, 3)\n",
      "Tensor(\"image_filters/conv2_1/Relu:0\", shape=(1, 104, 125, 3), dtype=float32)\n",
      "2\n",
      "2\n",
      "Total number of variables used  456 / 500000\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# todo: use tf.contrib.layers.conv2d for 3D filter\n",
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape, initializer=tf.random_normal_initializer())\n",
    "    biases = tf.get_variable(\"biases\", bias_shape, initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights, strides=[2, 2, 2, 2], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)\n",
    "\n",
    "def my_image_filter(input_images):\n",
    "    # Variables created here will be named \"convX/weights\", \"convX/biases\".\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        output = conv_relu(input_images, [5, 5, 3, 3], [3])\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        output = conv_relu(output, [5, 5, 3, 3], [3])\n",
    "    with tf.variable_scope(\"conv3\"):\n",
    "        return conv_relu(output, [5, 5, 3, 3], [3])\n",
    "\n",
    "def load(filename):\n",
    "    file = open(filename, \"r\") \n",
    "    image_names = file.readlines()\n",
    "    images = []\n",
    "    labels = []\n",
    "    counter = 1\n",
    "    with tf.variable_scope(\"image_filters\") as scope:\n",
    "        for name in image_names:\n",
    "            label = name[:3]\n",
    "            if label <= \"001\":\n",
    "                im = Image.open(\"images/\" + name.rstrip('\\n'))\n",
    "                H, W = im.size\n",
    "                pixels = list(im.getdata())\n",
    "                image = np.array([comp for pixel in pixels for comp in pixel]).reshape(-1, H, W, 3)\n",
    "\n",
    "                t_image = tf.convert_to_tensor(image)\n",
    "                t_image = tf.to_float(image)\n",
    "\n",
    "                images.append(t_image)\n",
    "                labels.append(label)\n",
    "            \n",
    "                print(image.shape)\n",
    "                print(my_image_filter(t_image))\n",
    "                scope.reuse_variables()\n",
    "\n",
    "                if counter >= 2:\n",
    "                    break\n",
    "                counter += 1\n",
    "#     print(len(images))\n",
    "#     print(len(labels))\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load('train.txt')\n",
    "\n",
    "# print('Input shape: ' + str(image_data.shape))\n",
    "# print('Labels shape: ' + str(label_data.shape))\n",
    "\n",
    "# num_classes = 200\n",
    "\n",
    "print( \"Total number of variables used \", np.sum([v.get_shape().num_elements() for v in tf.trainable_variables()]), '/', 500000 )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

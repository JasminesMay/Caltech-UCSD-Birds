{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "num_classes = 200\n",
    "\n",
    "def load(filename):\n",
    "    file = open(filename, \"r\") \n",
    "    image_names = file.readlines()\n",
    "    images = []\n",
    "    labels = []\n",
    "    for name in image_names:\n",
    "        label = int(name[:3])\n",
    "        if label <= 1:\n",
    "            im = Image.open(\"images/\" + name.rstrip('\\n'))\n",
    "            H, W = im.size\n",
    "            pixels = list(im.getdata())\n",
    "            if not type(pixels[0]) is int:\n",
    "                # todo: right now we are discarding transparent images\n",
    "                image = np.array([comp for pixel in pixels for comp in pixel]).reshape(-1, H, W, 3)\n",
    "                images.append(image)\n",
    "                # zero-index the label\n",
    "                labels.append(label - 1)\n",
    "    return images, labels\n",
    "\n",
    "images_train, labels_train = load('train.txt')\n",
    "# images_test, labels_test = load('test.txt')\n",
    "\n",
    "print(len(images_train))\n",
    "print(len(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([4, 0, 5, 1, 0, 0, 6, 4, 0, 3, 0, 0, 4, 2, 0, 0, 6, 0, 7, 4, 1, 3, 5,\n",
      "       3, 0, 7, 4, 5, 4, 5, 5, 0, 0, 3, 0, 5, 0, 5, 0, 6, 6, 6, 4, 5, 5, 4,\n",
      "       5, 0, 0, 5, 5, 6, 6, 6, 0, 0, 0, 6, 0, 6, 1, 5, 4, 7, 3, 7, 0, 5, 4,\n",
      "       3, 2, 5, 0, 0, 0, 0, 6, 3, 0, 0, 2, 6, 0, 3, 4, 7, 0, 0, 5, 0, 0, 1,\n",
      "       4, 0, 5, 5, 7, 4, 3, 6, 0, 0, 0, 4, 0, 0, 5, 2, 0, 6, 2, 0, 4, 2, 7,\n",
      "       7, 5, 0, 0, 2, 5, 5, 0, 4, 4, 0, 3, 3, 5, 5, 3, 5, 0, 0, 6, 0, 5, 0,\n",
      "       5, 6, 7, 2, 0, 2, 0, 0, 0, 0, 0, 5, 5, 0, 0, 5, 7, 0, 5, 5, 2, 5, 4,\n",
      "       3, 0, 0, 3, 2, 5, 0, 0, 2, 3, 6, 5, 0, 0, 6, 4, 5, 5, 5, 0, 5, 0, 5,\n",
      "       5, 5, 7, 5, 0, 4, 4, 1, 0, 3, 5, 4, 0, 5, 0, 7])]\n"
     ]
    }
   ],
   "source": [
    "# todo: use tf.contrib.layers.conv2d for 3D filter\n",
    "def conv_relu(input_image, kernel_shape, bias_shape, stride = 2):\n",
    "    strides = [1, stride, stride, 1]\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape, initializer=tf.random_normal_initializer())\n",
    "    biases = tf.get_variable(\"biases\", bias_shape, initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input_image, weights, strides=strides, padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)\n",
    "\n",
    "def conv_layers(input_image):\n",
    "    # Variables created here will be named \"convX/weights\", \"convX/biases\".\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        out_channels = 15\n",
    "        output = conv_relu(input_image, [5, 5, 3, out_channels], [out_channels], stride=1)\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        old_out_channels = out_channels\n",
    "        out_channels = 20\n",
    "        output = conv_relu(output, [5, 5, old_out_channels, out_channels], [out_channels])\n",
    "    with tf.variable_scope(\"conv3\"):\n",
    "        old_out_channels = out_channels\n",
    "        out_channels = 3\n",
    "        return conv_relu(output, [5, 5, old_out_channels, out_channels], [out_channels])\n",
    "\n",
    "def max_pool_2d_nxn_regions(inputs, output_size):\n",
    "    inputs_shape = tf.shape(inputs)\n",
    "    h = tf.cast(tf.gather(inputs_shape, 1), tf.int32)\n",
    "    w = tf.cast(tf.gather(inputs_shape, 2), tf.int32)\n",
    "    \n",
    "    pooling_op = tf.reduce_max\n",
    "    \n",
    "#         pooling_op = tf.reduce_mean\n",
    "\n",
    "    result = []\n",
    "    n = output_size\n",
    "    for row in range(output_size):\n",
    "        for col in range(output_size):\n",
    "            # start_h = floor(row / n * h)\n",
    "            start_h = tf.cast(tf.floor(tf.multiply(row / n, tf.cast(h, tf.float32))), tf.int32)\n",
    "            # end_h = ceil((row + 1) / n * h)\n",
    "            end_h = tf.cast(tf.ceil(tf.multiply((row + 1) / n, tf.cast(h, tf.float32))), tf.int32)\n",
    "            # start_w = floor(col / n * w)\n",
    "            start_w = tf.cast(tf.floor(tf.multiply(col / n, tf.cast(w, tf.float32))), tf.int32)\n",
    "            # end_w = ceil((col + 1) / n * w)\n",
    "            end_w = tf.cast(tf.ceil(tf.multiply((col + 1) / n, tf.cast(w, tf.float32))), tf.int32)\n",
    "            pooling_region = inputs[:, start_h:end_h, start_w:end_w, :]\n",
    "            pool_result = pooling_op(pooling_region, axis=(1, 2))\n",
    "            result.append(pool_result)\n",
    "    return result\n",
    "\n",
    "# Modified from RikHeijdens on https://github.com/tensorflow/tensorflow/issues/6011\n",
    "def spp_layer(inputs, dimensions=[3, 2, 1]):\n",
    "    # todo: fix this\n",
    "    # print(inputs.get_shape()[1] < tf.constant(36, dtype=tf.int32))\n",
    "\n",
    "\n",
    "#     if tf.less(inputs.get_shape()[1], dimensions[0] ** 2) or tf.less(inputs.get_shape()[2], dimensions[0] ** 2):\n",
    "#         print(shape)\n",
    "#         print('Size must be greater than {:d}x{:d}'.format(dimensions[0], dimensions[0]))\n",
    "#         return None\n",
    "    pool_list = []\n",
    "    for pool_dim in dimensions:\n",
    "        pool_list += max_pool_2d_nxn_regions(inputs, pool_dim)\n",
    "    return tf.concat(pool_list, axis=1)\n",
    "\n",
    "# todo: might be able to move this into session\n",
    "def fc_layer(image, reuse):\n",
    "    return tf.contrib.layers.fully_connected(image, num_classes, activation_fn=None, scope=\"fc\", reuse=reuse)\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "tf.reset_default_graph()\n",
    "fc_reuse = False\n",
    "with tf.variable_scope(\"network\") as scope:\n",
    "    image_placeholders = []\n",
    "    label_placeholders = []\n",
    "\n",
    "    logits = []\n",
    "    logit_labels = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        image = tf.placeholder(tf.float32, (1,None,None,3), name='image_%d'%(i))\n",
    "        image_placeholders.append(image)\n",
    "        label = tf.placeholder(tf.int32, name='label_%d'%(i))\n",
    "        label_placeholders.append(label)\n",
    "    \n",
    "        logit = tf.to_float(image)\n",
    "        logit = conv_layers(logit)\n",
    "        logit = spp_layer(logit)\n",
    "\n",
    "        if not logit is None:\n",
    "            logit = fc_layer(logit, fc_reuse)\n",
    "            logit = tf.reshape(logit, [-1])\n",
    "            logits.append(logit)\n",
    "            logit_labels.append(label)\n",
    "            fc_reuse = True\n",
    "\n",
    "        scope.reuse_variables()\n",
    "    \n",
    "# output = tf.identity(logits, name='output')\n",
    "logits = tf.convert_to_tensor(logits)\n",
    "test = tf.argmax(logits, 0)\n",
    "# test_2 = tf.argmax(logits, 1)\n",
    "\n",
    "# loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=logit_labels))\n",
    "# regularization_loss = tf.losses.get_regularization_loss()\n",
    "# total_loss = loss + 1e-6 * regularization_loss\n",
    "# optimizer = tf.train.MomentumOptimizer(0.001, 0.9)\n",
    "# with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "#     opt = optimizer.minimize(total_loss)\n",
    "# correct = tf.equal(tf.argmax(logits, 0), logit_labels)\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "# session.run([accuracy], feed_dict={image: images_train[0]})\n",
    "image_data = images_train[:batch_size]\n",
    "label_data = labels_train[:batch_size]\n",
    "fd = {**{i: d for i, d in zip(image_placeholders, image_data)}, **{i: d for i, d in zip(label_placeholders, label_data )}}\n",
    "# accuracy_val, loss_val, _  = session.run([accuracy, total_loss, opt], feed_dict=fd)\n",
    "\n",
    "test = session.run([test], feed_dict=fd)\n",
    "\n",
    "print(test)\n",
    "# print(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "####################################### PART ONE #######################################\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import datetime\n",
    "\n",
    "NUM_CLASSES = 200\n",
    "LIMIT = 40\n",
    "NUM_CLASSES = LIMIT\n",
    "\n",
    "IMAGES_MEAN = 122.5\n",
    "IMAGES_STD = 63.32\n",
    "\n",
    "LOGITS_COLLECTION = 'LOGITS'\n",
    "LOGIT_LABELS_COLLECTION = 'LOGIT-LABELS'\n",
    "\n",
    "RUN_PREFIX = datetime.datetime.fromtimestamp(datetime.datetime.now().timestamp()).strftime('%Y-%m-%d-%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199\n",
      "1089\n"
     ]
    }
   ],
   "source": [
    "def load(filename):\n",
    "    file = open(filename, \"r\") \n",
    "    image_names = file.readlines()\n",
    "    images = []\n",
    "    labels = []\n",
    "    for name in image_names:\n",
    "        label = int(name[:3])\n",
    "        if label <= LIMIT:\n",
    "            im = Image.open(\"images/\" + name.rstrip('\\n'))\n",
    "            H, W = im.size\n",
    "            pixels = list(im.getdata())\n",
    "            if not type(pixels[0]) is int:\n",
    "                # todo: right now we are discarding transparent images\n",
    "                image = np.array([comp for pixel in pixels for comp in pixel]).reshape(-1, H, W, 3)\n",
    "                images.append(image)\n",
    "                # zero-index the label\n",
    "                labels.append(label - 1)\n",
    "        else: \n",
    "            break\n",
    "    return images, labels\n",
    "\n",
    "images_train, labels_train = load('train.txt')\n",
    "images_test, labels_test = load('test.txt')\n",
    "\n",
    "print(len(images_train))\n",
    "print(len(images_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 150)\n",
      "network/conv/kernel:0\n",
      "network/conv/bias:0\n",
      "fc2/weights:0\n",
      "fc2/biases:0\n",
      "fc3/weights:0\n",
      "fc3/biases:0\n",
      "network/conv/kernel/Momentum:0\n",
      "network/conv/bias/Momentum:0\n",
      "fc2/weights/Momentum:0\n",
      "fc2/biases/Momentum:0\n",
      "fc3/weights/Momentum:0\n",
      "fc3/biases/Momentum:0\n",
      "Number of trainable variables: 6\n",
      "Total number of variables used 28729\n",
      "ready to test\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "# OUT_CHANNEL_SIZES = [15, 30, 25, 18]\n",
    "\n",
    "# todo: use tf.contrib.layers.conv2d for 3D filter\n",
    "# def conv_relu(input_image, kernel_shape, bias_shape, stride = 2):\n",
    "#     strides = [1, stride, stride, 1]\n",
    "#     weights = tf.get_variable(\"weights\", kernel_shape, initializer=tf.random_normal_initializer())\n",
    "#     biases = tf.get_variable(\"biases\", bias_shape, initializer=tf.constant_initializer(0.0))\n",
    "#     conv = tf.nn.conv2d(input_image, weights, strides=strides, padding='SAME')\n",
    "#     return tf.nn.relu(conv + biases)\n",
    "\n",
    "# def conv_layers(input_image, filter_height=5, filter_width=5, in_channels=3):\n",
    "#     # Variables created here will be named \"convX/weights\", \"convX/biases\".\n",
    "#     with tf.variable_scope(\"conv1\"):\n",
    "#         out_channels = OUT_CHANNEL_SIZES[0]\n",
    "#         output = conv_relu(\n",
    "#             input_image, \n",
    "#             kernel_shape=[filter_height, filter_width, in_channels, out_channels], \n",
    "#             bias_shape=[out_channels],\n",
    "#             stride=1\n",
    "#             )\n",
    "# #     with tf.variable_scope(\"conv2\"):\n",
    "#         old_out_channels = out_channels\n",
    "#         out_channels = OUT_CHANNEL_SIZES[1]\n",
    "#         output = conv_relu(\n",
    "#             output, \n",
    "#             kernel_shape=[filter_height, filter_width, old_out_channels, out_channels], \n",
    "#             bias_shape=[out_channels]\n",
    "#             )\n",
    "#     with tf.variable_scope(\"conv3\"):\n",
    "#         old_out_channels = out_channels\n",
    "#         out_channels = OUT_CHANNEL_SIZES[2]\n",
    "#         output = conv_relu(\n",
    "#             output, \n",
    "#             kernel_shape=[filter_height, filter_width, old_out_channels, out_channels], \n",
    "#             bias_shape=[out_channels]\n",
    "#             )\n",
    "#     with tf.variable_scope(\"conv4\"):\n",
    "#         old_out_channels = out_channels\n",
    "#         out_channels = OUT_CHANNEL_SIZES[3]\n",
    "#         return conv_relu(\n",
    "#             output, \n",
    "#             kernel_shape=[filter_height, filter_width, old_out_channels, out_channels], \n",
    "#             bias_shape=[out_channels]\n",
    "#             )\n",
    "\n",
    "# Modified from RikHeijdens on https://github.com/tensorflow/tensorflow/issues/6011\n",
    "def spp_layer(image, dimensions=[6, 3, 2, 1]):\n",
    "    # todo: fix this\n",
    "    if tf.less(tf.shape(image)[1], dimensions[0] ** 2) is True:\n",
    "        return None\n",
    "    if tf.less(tf.shape(image)[2], dimensions[0] ** 2) is True:\n",
    "        return None\n",
    "    pool_list = []\n",
    "    for pool_dim in dimensions:\n",
    "        pool_list += max_pool_2d_nxn_regions(image, pool_dim)\n",
    "    return tf.concat(pool_list, axis=1)\n",
    "\n",
    "def max_pool_2d_nxn_regions(inputs, output_size):\n",
    "    inputs_shape = tf.shape(inputs)\n",
    "    h = tf.cast(tf.gather(inputs_shape, 1), tf.int32)\n",
    "    w = tf.cast(tf.gather(inputs_shape, 2), tf.int32)\n",
    "\n",
    "    result = []\n",
    "    n = output_size\n",
    "    for row in range(output_size):\n",
    "        for col in range(output_size):\n",
    "            # start_h = floor(row / n * h)\n",
    "            start_h = tf.cast(tf.floor(tf.multiply(row / n, tf.cast(h, tf.float32))), tf.int32)\n",
    "            # end_h = ceil((row + 1) / n * h)\n",
    "            end_h = tf.cast(tf.ceil(tf.multiply((row + 1) / n, tf.cast(h, tf.float32))), tf.int32)\n",
    "            # start_w = floor(col / n * w)\n",
    "            start_w = tf.cast(tf.floor(tf.multiply(col / n, tf.cast(w, tf.float32))), tf.int32)\n",
    "            # end_w = ceil((col + 1) / n * w)\n",
    "            end_w = tf.cast(tf.ceil(tf.multiply((col + 1) / n, tf.cast(w, tf.float32))), tf.int32)\n",
    "            pooling_region = inputs[:, start_h:end_h, start_w:end_w, :]\n",
    "            pool_result = tf.reduce_max(pooling_region, axis=(1, 2))\n",
    "            result.append(pool_result)\n",
    "    return result\n",
    "\n",
    "\n",
    "TEST_LOGITS_COLLECTION_BCONV = 'TEST_LOGITS_COLLECTION_BCONV'\n",
    "TEST_LOGITS_COLLECTION = 'TEST_LOGITS_COLLECTION'\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    image_placeholders = []\n",
    "    label_placeholders = []\n",
    "\n",
    "    with tf.variable_scope(\"network\") as scope:\n",
    "        conv_reuse = None\n",
    "        for i in range(BATCH_SIZE):\n",
    "            # todo: we can add transparent images \n",
    "            image = tf.placeholder(tf.float32, shape=(1,None,None,3), name='image_{}'.format(i))\n",
    "            image_placeholders.append(image)\n",
    "            label = tf.placeholder(tf.int64, shape=(), name='label_{}'.format(i))\n",
    "            label_placeholders.append(label)\n",
    "\n",
    "            logit = tf.to_float(image)\n",
    "            logit = (logit - IMAGES_MEAN) / IMAGES_STD\n",
    "#             logit = conv_layers(logit)\n",
    "            tf.add_to_collection(TEST_LOGITS_COLLECTION_BCONV, tf.identity(logit, name='{}_{}'.format(TEST_LOGITS_COLLECTION_BCONV, i)))\n",
    "            logit = tf.layers.conv2d(logit, 3, [2, 2], padding='SAME', reuse=conv_reuse, name='conv')\n",
    "            conv_reuse = True\n",
    "            tf.add_to_collection(TEST_LOGITS_COLLECTION, tf.identity(logit, name='{}_{}'.format(TEST_LOGITS_COLLECTION, i)))\n",
    "            logit = spp_layer(logit)\n",
    "\n",
    "            if not logit is None:\n",
    "                logit = tf.reshape(logit, [-1])\n",
    "                tf.add_to_collection(LOGITS_COLLECTION, tf.identity(logit, name='coll_logit_{}'.format(i)))\n",
    "                tf.add_to_collection(LOGIT_LABELS_COLLECTION, tf.identity(label, name='coll_label_{}'.format(i)))\n",
    "\n",
    "            scope.reuse_variables()\n",
    "        \n",
    "    logits_TEST_BCONV = tf.get_collection(TEST_LOGITS_COLLECTION_BCONV)\n",
    "    logits_TEST = tf.get_collection(TEST_LOGITS_COLLECTION)\n",
    "    \n",
    "    logits = tf.stack(tf.get_collection(LOGITS_COLLECTION))\n",
    "    logit_labels = tf.stack(tf.get_collection(LOGIT_LABELS_COLLECTION))\n",
    "    print(logits.shape)\n",
    "\n",
    "#     logits = tf.contrib.layers.fully_connected(logits, 650, activation_fn=tf.nn.relu, scope=\"fc1\")\n",
    "    logits = tf.contrib.layers.fully_connected(logits, 150, activation_fn=tf.nn.relu, scope=\"fc2\")\n",
    "    logits = tf.contrib.layers.fully_connected(logits, NUM_CLASSES, activation_fn=None, scope=\"fc3\")\n",
    "\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=logit_labels)) + 1e-6 * tf.losses.get_regularization_loss()\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        opt = tf.train.MomentumOptimizer(0.001, 0.9).minimize(loss)\n",
    "    correct = tf.equal(tf.argmax(logits, -1), logit_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    [print(v.name) for v in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)]\n",
    "    print('Number of trainable variables: {}'.format(len(tf.trainable_variables())))\n",
    "    print('Total number of variables used {}'.format(np.sum([v.get_shape().num_elements() for v in tf.trainable_variables()])))\n",
    "    \n",
    "sess = tf.Session(graph=graph)\n",
    "LOG_DIR = 'log/{}'.format(RUN_PREFIX)\n",
    "with graph.as_default(), sess.as_default():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('ready to test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to test\n",
      "[  0] Accuracy: 0.071  \t  Loss: 3.598  \t  validation accuracy: 0.063\n",
      "[  1] Accuracy: 0.076  \t  Loss: 3.573  \t  validation accuracy: 0.078\n",
      "[  2] Accuracy: 0.097  \t  Loss: 3.543  \t  validation accuracy: 0.092\n",
      "[  3] Accuracy: 0.100  \t  Loss: 3.511  \t  validation accuracy: 0.088\n",
      "[  4] Accuracy: 0.111  \t  Loss: 3.475  \t  validation accuracy: 0.103\n",
      "[  5] Accuracy: 0.108  \t  Loss: 3.431  \t  validation accuracy: 0.113\n",
      "[  6] Accuracy: 0.120  \t  Loss: 3.391  \t  validation accuracy: 0.117\n",
      "[  7] Accuracy: 0.126  \t  Loss: 3.347  \t  validation accuracy: 0.111\n",
      "[  8] Accuracy: 0.136  \t  Loss: 3.304  \t  validation accuracy: 0.122\n",
      "[  9] Accuracy: 0.142  \t  Loss: 3.267  \t  validation accuracy: 0.124\n",
      "[ 10] Accuracy: 0.143  \t  Loss: 3.222  \t  validation accuracy: 0.132\n",
      "[ 11] Accuracy: 0.157  \t  Loss: 3.174  \t  validation accuracy: 0.146\n",
      "[ 12] Accuracy: 0.153  \t  Loss: 3.137  \t  validation accuracy: 0.144\n",
      "[ 13] Accuracy: 0.164  \t  Loss: 3.098  \t  validation accuracy: 0.152\n",
      "[ 14] Accuracy: 0.184  \t  Loss: 3.057  \t  validation accuracy: 0.153\n",
      "[ 15] Accuracy: 0.171  \t  Loss: 3.037  \t  validation accuracy: 0.153\n",
      "[ 16] Accuracy: 0.190  \t  Loss: 2.984  \t  validation accuracy: 0.146\n",
      "[ 17] Accuracy: 0.190  \t  Loss: 2.956  \t  validation accuracy: 0.150\n",
      "[ 18] Accuracy: 0.200  \t  Loss: 2.929  \t  validation accuracy: 0.169\n",
      "[ 19] Accuracy: 0.203  \t  Loss: 2.894  \t  validation accuracy: 0.154\n"
     ]
    }
   ],
   "source": [
    "####################################### PART THREE #######################################\n",
    "print('starting to test')\n",
    "with graph.as_default(), sess.as_default():\n",
    "#     writer = tf.summary.FileWriter(LOG_DIR)\n",
    "#     writer.add_graph(sess.graph)\n",
    "    for epoch in range(EPOCHS):\n",
    "        np.random.seed(epoch)\n",
    "        np.random.shuffle(images_train)\n",
    "        np.random.seed(epoch)\n",
    "        np.random.shuffle(labels_train)\n",
    "        accuracy_vals, loss_vals = [], []\n",
    "        for i in range(0, len(images_train) - BATCH_SIZE + 1, BATCH_SIZE):\n",
    "            batch_images, batch_labels = images_train[i:i + BATCH_SIZE], labels_train[i:i + BATCH_SIZE]\n",
    "        \n",
    "            # todo: this is not very good... (probably replace with 1 x 1 x 1 x 1 when I implement SPP filter, do the same for training)\n",
    "            if BATCH_SIZE - len(batch_images) > 0:\n",
    "#                 print('testing diff: %d'%(BATCH_SIZE - len(batch_images)))\n",
    "                for j in range(len(batch_images), BATCH_SIZE):\n",
    "                    batch_images.append(images_train[j - len(batch_images)])\n",
    "                    batch_labels.append(labels_train[j - len(batch_images)])\n",
    "\n",
    "            fd = {**{k: v for k, v in zip(image_placeholders, batch_images)}, **{k: v for k, v in zip(label_placeholders, batch_labels )}}\n",
    "\n",
    "            accuracy_val, loss_val, _ = sess.run([accuracy, loss, opt], feed_dict=fd)\n",
    "            accuracy_vals.append(accuracy_val)\n",
    "            loss_vals.append(loss_val)\n",
    "            \n",
    "#             if i >= BATCH_SIZE * 3:\n",
    "#                 o_logits, o_logits_TEST, o_logits_TEST_BCONV = sess.run([logits, logits_TEST, logits_TEST_BCONV], feed_dict=fd)\n",
    "#                 print('[{}:{}] LOGIT LEN: {} ACC: {} LOSS: {}'.format(epoch, i, len(o_logits), accuracy_val, loss_val))\n",
    "#                 print(o_logits_TEST_BCONV[0])\n",
    "#                 print('[{}:{}] ==========================='.format(epoch, i))\n",
    "#                 print(o_logits_TEST[0])\n",
    "        val_correct = []\n",
    "        for i in range(0, len(images_test), BATCH_SIZE):\n",
    "            batch_images, batch_labels = images_test[i:i + BATCH_SIZE], labels_test[i:i + BATCH_SIZE]\n",
    "            \n",
    "            if BATCH_SIZE - len(batch_images) > 0:\n",
    "#                 print('training diff: %d'%(BATCH_SIZE - len(batch_images)))\n",
    "                for j in range(len(batch_images), BATCH_SIZE):\n",
    "                    batch_images.append(images_test[j - len(batch_images)])\n",
    "                    batch_labels.append(labels_test[j - len(batch_images)])\n",
    "                \n",
    "            fd = {**{k: v for k, v in zip(image_placeholders, batch_images)}, **{k: v for k, v in zip(label_placeholders, batch_labels )}}\n",
    "            c = sess.run(correct, feed_dict=fd)\n",
    "            val_correct.extend(c)\n",
    "\n",
    "        # s = tf.Summary()\n",
    "        # s.value.add(simple_value=np.mean(accuracy_vals), tag=\"accuracy\")\n",
    "        # s.value.add(simple_value=np.mean(loss_vals), tag=\"loss\")\n",
    "        # s.value.add(simple_value=np.mean(val_correct), tag=\"correct\")\n",
    "        # writer.add_summary(s, epoch)\n",
    "        # writer.flush()\n",
    "        # saver.save(sess, path.join(RUN_PREFIX, 'network.ckpt'), global_step=epoch)\n",
    "        print('[%3d] Accuracy: %0.3f  \\t  Loss: %0.3f  \\t  validation accuracy: %0.3f'%(epoch, np.mean(accuracy_vals), np.mean(loss_vals), np.mean(val_correct)))\n",
    "\n",
    "\n",
    "# sess.run([accuracy], feed_dict={image: images_train[0]})\n",
    "# batch_images = images_train[:BATCH_SIZE]\n",
    "# batch_labels = labels_train[:BATCH_SIZE]\n",
    "# fd = {**{i: d for i, d in zip(image_placeholders, batch_images)}, **{i: d for i, d in zip(label_placeholders, batch_labels )}}\n",
    "# accuracy_val, loss_val, _  = sess.run([accuracy, total_loss, opt], feed_dict=fd)\n",
    "# print(accuracy_val)\n",
    "# print(loss_val)\n",
    "# print(logits[0])\n",
    "\n",
    "# batch_images = images_train[BATCH_SIZE:BATCH_SIZE+BATCH_SIZE]\n",
    "# batch_labels = labels_train[BATCH_SIZE:BATCH_SIZE+BATCH_SIZE]\n",
    "# accuracy_val, loss_val, _  = session.run([accuracy, total_loss, opt], feed_dict=fd)\n",
    "# print(accuracy_val)\n",
    "# print(loss_val)\n",
    "\n",
    "# print(logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
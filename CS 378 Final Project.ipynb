{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "num_classes = 200\n",
    "\n",
    "def load(filename):\n",
    "    file = open(filename, \"r\") \n",
    "    image_names = file.readlines()\n",
    "    images = []\n",
    "    labels = []\n",
    "    for name in image_names:\n",
    "        label = int(name[:3])\n",
    "        if label <= 5:\n",
    "            im = Image.open(\"images/\" + name.rstrip('\\n'))\n",
    "            H, W = im.size\n",
    "            pixels = list(im.getdata())\n",
    "            if not type(pixels[0]) is int:\n",
    "                # todo: right now we are discarding transparent images\n",
    "                image = np.array([comp for pixel in pixels for comp in pixel]).reshape(-1, H, W, 3)\n",
    "                images.append(image)\n",
    "                # zero-index the label\n",
    "                labels.append(label - 1)\n",
    "    return images, labels\n",
    "\n",
    "images_train, labels_train = load('train.txt')\n",
    "\n",
    "print(len(images_train))\n",
    "print(len(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not iterable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a9f1909ed801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"network\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mfc_reuse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelscaria/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    474\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0minvoked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \"\"\"\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'Tensor' object is not iterable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not iterable."
     ]
    }
   ],
   "source": [
    "# todo: use tf.contrib.layers.conv2d for 3D filter\n",
    "def conv_relu(input_image, kernel_shape, bias_shape, stride = 2):\n",
    "    strides = [stride, stride, stride, stride]\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape, initializer=tf.random_normal_initializer())\n",
    "    biases = tf.get_variable(\"biases\", bias_shape, initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input_image, weights, strides=strides, padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)\n",
    "\n",
    "def conv_layers(input_image):\n",
    "    # Variables created here will be named \"convX/weights\", \"convX/biases\".\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        out_channels = 15\n",
    "        output = conv_relu(input_image, [5, 5, 3, out_channels], [out_channels], stride=1)\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        old_out_channels = out_channels\n",
    "        out_channels = 20\n",
    "        output = conv_relu(output, [5, 5, old_out_channels, out_channels], [out_channels])\n",
    "    with tf.variable_scope(\"conv3\"):\n",
    "        old_out_channels = out_channels\n",
    "        out_channels = 3\n",
    "        return conv_relu(output, [5, 5, old_out_channels, out_channels], [out_channels])\n",
    "    \n",
    "# https://github.com/tensorflow/tensorflow/issues/6011\n",
    "def spp_layer(image, levels=[6, 3, 2, 1]):\n",
    "    shape = image.get_shape().as_list()\n",
    "    if shape[1] < levels[0] ** 2 or shape[2] < levels[0] ** 2:\n",
    "        print(shape)\n",
    "        print('Size must be greater than {:d}x{:d}'.format(levels[0], levels[0]))\n",
    "        return None\n",
    "\n",
    "    with tf.variable_scope('spp'):\n",
    "        pool_outputs = []\n",
    "        for level in levels:\n",
    "            # todo: figure out why it is surrounded by 1\n",
    "            window_size = [1] + [np.ceil(d / level).astype(np.int32) for d in shape[1:3]] + [1]\n",
    "            strides = [1] + [np.floor(d / level + 1).astype(np.int32) for d in shape[1:3]] + [1]\n",
    "            \n",
    "            pool = tf.nn.max_pool(image, ksize=window_size, strides=strides, padding='SAME')\n",
    "            pool_outputs.append(tf.reshape(pool, [shape[0], -1]))\n",
    "        spp_pool = tf.concat(pool_outputs, axis=1)\n",
    "    return spp_pool\n",
    "\n",
    "def fc_layer(image, reuse):\n",
    "    return tf.contrib.layers.fully_connected(image, num_classes, activation_fn=None, scope=\"fc\", reuse=reuse)\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, (None,None,None,3))\n",
    "labels = tf.placeholder(tf.int64, (None), name='labels')\n",
    "\n",
    "logits = []\n",
    "logit_labels = []\n",
    "\n",
    "with tf.variable_scope(\"network\") as scope:\n",
    "    fc_reuse = False\n",
    "    for index, image in enumerate(inputs):\n",
    "        output = tf.convert_to_tensor(image)\n",
    "        output = tf.to_float(output)\n",
    "        output = conv_layers(output)\n",
    "        output = spp_layer(output)\n",
    "        if not output is None:\n",
    "            output = fc_layer(output, fc_reuse)\n",
    "            output = tf.reshape(output, [-1])\n",
    "            logits.append(output)\n",
    "            logit_labels.append(labels[index])\n",
    "            fc_reuse = True\n",
    "\n",
    "        scope.reuse_variables()\n",
    "\n",
    "    print(logits)\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=logit_labels))\n",
    "\n",
    "regularization_loss = tf.losses.get_regularization_loss()\n",
    "total_loss = loss + 1e-6 * regularization_loss\n",
    "# todo: play around with optimizer\n",
    "optimizer = tf.train.MomentumOptimizer(0.001, 0.9)\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    opt = optimizer.minimize(total_loss)\n",
    "correct = tf.equal(tf.argmax(logits, 1), logit_labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "print( \"Total number of variables used: \", np.sum([v.get_shape().num_elements() for v in tf.trainable_variables()]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test, labels_test = load('test.txt')\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    np.random.seed(epoch)\n",
    "    np.random.shuffle(images_train)\n",
    "    np.random.seed(epoch)\n",
    "    np.random.shuffle(labels_train)\n",
    "    accuracy_vals, loss_vals = [], []\n",
    "    \n",
    "    for i in range(0, images_train.shape[0] - batch_size + 1, batch_size):\n",
    "        batch_images, batch_labels = images_train[i:i + batch_size], labels_train[i:i + batch_size]\n",
    "        accuracy_val, loss_val, _ = sess.run([accuracy, total_loss, opt], feed_dict={inputs: batch_images, labels: batch_labels})\n",
    "        accuracy_vals.append(accuracy_val)\n",
    "        loss_vals.append(loss_val)\n",
    "\n",
    "    val_correct = []\n",
    "    for i in range(0, image_test.shape[0], batch_size):\n",
    "        batch_images, batch_labels = image_val[i:i + batch_size], label_val[i:i + batch_size]\n",
    "        val_correct.extend( sess.run(correct, feed_dict={inputs: batch_images, labels: batch_labels}) )\n",
    "    print('[%3d] Accuracy: %0.3f  \\t  Loss: %0.3f  \\t  validation accuracy: %0.3f'%(epoch, np.mean(accuracy_vals), np.mean(loss_vals), np.mean(val_correct)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FAILED SPPs\n",
    "# # https://github.com/tensorflow/tensorflow/issues/6011\n",
    "# def spp_layer(image, levels=[6, 3, 2, 1], name = 'SPP_layer'):\n",
    "#     shape = image.get_shape()[1:3].as_list()\n",
    "#     with tf.variable_scope(name):\n",
    "#         pool_outputs = []\n",
    "#         print(image.shape)\n",
    "#         for level in levels:\n",
    "#             window_size = [np.ceil(d / level).astype(np.int32) for d in shape]\n",
    "#             strides = [np.floor(d / level + 1).astype(np.int32) for d in shape]\n",
    "            \n",
    "#             # todo: figure out why it is surrounded by 1 \n",
    "#             ksize = [1, window_size[0], window_size[1], 1]\n",
    "#             strides = [1, strides[0], strides[1], 1]\n",
    "            \n",
    "#             print(ksize)\n",
    "#             print(strides)\n",
    "            \n",
    "#             pool = tf.nn.max_pool(image, ksize=ksize, strides=strides, padding='SAME')\n",
    "#             pool_outputs.append(tf.reshape(pool, [shape[0], -1]))\n",
    "#         spp_pool = tf.concat(pool_outputs, axis=1)\n",
    "#         print(spp_pool)\n",
    "#     return spp_pool\n",
    "\n",
    "# # https://github.com/tensorflow/tensorflow/issues/6011\n",
    "# def spp_layer(image, levels=[6, 3, 2, 1], name = 'SPP_layer'):\n",
    "#     shape = image.get_shape().as_list()\n",
    "#     with tf.variable_scope(name):\n",
    "#         pool_outputs = []\n",
    "#         for level in levels:\n",
    "#             # todo: figure out why it is surrounded by 1 \n",
    "#             window_size = [1] + [np.ceil(d / level).astype(np.int32) for d in shape[1:3]] + [1]\n",
    "#             strides = [1, np.floor(shape[1] / level + 1).astype(np.int32), np.floor(shape[2] / level + 1), 1]\n",
    "            \n",
    "#             pool = tf.nn.max_pool(image, ksize=window_size, strides=strides, padding='SAME')\n",
    "#             pool_outputs.append(tf.reshape(pool, [shape[0], -1]))\n",
    "#         spp_pool = tf.concat(pool_outputs, axis=1)\n",
    "#     return spp_pool\n",
    "\n",
    "# MISC\n",
    "\n",
    "# def conv_layers(input_image):\n",
    "#     # Variables created here will be named \"convX/weights\", \"convX/biases\".\n",
    "#     with tf.variable_scope(\"conv1\"):\n",
    "#         out_channels = 10\n",
    "#         output = conv_relu(input_image, [15, 15, 3, out_channels], [out_channels])\n",
    "#     with tf.variable_scope(\"conv2\"):\n",
    "#         old_out_channels = out_channels\n",
    "#         out_channels = 15\n",
    "#         output = conv_relu(output, [5, 5, old_out_channels, out_channels], [out_channels])\n",
    "#     with tf.variable_scope(\"conv3\"):\n",
    "#         old_out_channels = out_channels\n",
    "#         out_channels = 15\n",
    "#         output = conv_relu(output, [5, 5, old_out_channels, out_channels], [out_channels])\n",
    "#     with tf.variable_scope(\"conv4\"):\n",
    "#         old_out_channels = out_channels\n",
    "#         out_channels = 3\n",
    "#         return conv_relu(output, [5, 5, old_out_channels, out_channels], [out_channel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

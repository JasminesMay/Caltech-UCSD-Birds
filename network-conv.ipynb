{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "####################################### PART ONE #######################################\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import util\n",
    "\n",
    "NUM_CLASSES = 200\n",
    "LIMIT = 20\n",
    "NUM_CLASSES = LIMIT\n",
    "\n",
    "IMAGES_MEAN = 122.5\n",
    "IMAGES_STD = 63.32\n",
    "\n",
    "LOGITS_COLLECTION = 'LOGITS'\n",
    "LOGIT_LABELS_COLLECTION = 'LOGIT-LABELS'\n",
    "\n",
    "RUN_PREFIX = datetime.datetime.fromtimestamp(datetime.datetime.now().timestamp()).strftime('%Y-%m-%d-%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "480\n",
      "480\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "def load(filename):\n",
    "    file = open(filename, \"r\") \n",
    "    image_names = file.readlines()\n",
    "    images = []\n",
    "    labels = []\n",
    "    for name in image_names:\n",
    "        label = int(name[:3])\n",
    "        if label <= LIMIT:\n",
    "            im = Image.open(\"images/\" + name.rstrip('\\n'))\n",
    "            H, W = im.size\n",
    "            pixels = list(im.getdata())\n",
    "            if not type(pixels[0]) is int:\n",
    "                # todo: right now we are discarding transparent images\n",
    "                image = np.array([comp for pixel in pixels for comp in pixel]).reshape(-1, H, W, 3)\n",
    "                images.append(image)\n",
    "                # zero-index the label\n",
    "                labels.append(label - 1)\n",
    "        else: \n",
    "            break\n",
    "    return images, labels\n",
    "\n",
    "images_train_and_val, labels_train_and_val = load('train.txt')\n",
    "# images_test, labels_test = load('test.txt')\n",
    "\n",
    "\n",
    "seed = 139582935\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(images_train_and_val)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(labels_train_and_val)\n",
    "\n",
    "\n",
    "images_train = images_train_and_val[:int(len(images_train_and_val) * .80)]\n",
    "images_val = images_train_and_val[int(len(images_train_and_val) * .80):]\n",
    "\n",
    "labels_train = labels_train_and_val[:int(len(labels_train_and_val) * .80)]\n",
    "labels_val = labels_train_and_val[int(len(labels_train_and_val) * .80):]\n",
    "\n",
    "\n",
    "print(len(images_train))\n",
    "print(len(images_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 750)\n",
      "network/conv-1/kernel:0\n",
      "network/conv-1/bias:0\n",
      "network/conv-2/kernel:0\n",
      "network/conv-2/bias:0\n",
      "network/conv-3/kernel:0\n",
      "network/conv-3/bias:0\n",
      "fc-2/weights:0\n",
      "fc-2/biases:0\n",
      "network/conv-1/kernel/Momentum:0\n",
      "network/conv-1/bias/Momentum:0\n",
      "network/conv-2/kernel/Momentum:0\n",
      "network/conv-2/bias/Momentum:0\n",
      "network/conv-3/kernel/Momentum:0\n",
      "network/conv-3/bias/Momentum:0\n",
      "fc-2/weights/Momentum:0\n",
      "fc-2/biases/Momentum:0\n",
      "Number of trainable variables: 8\n",
      "Total number of variables used 22620\n",
      "ready to test\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 25\n",
    "EPOCHS = 75\n",
    "\n",
    "# Modified from RikHeijdens on https://github.com/tensorflow/tensorflow/issues/6011\n",
    "def spp_layer(image, dimensions=[6, 3, 2, 1]):\n",
    "    # todo: fix this\n",
    "    if tf.less(tf.shape(image)[1], dimensions[0] ** 2) is True:\n",
    "        return None\n",
    "    if tf.less(tf.shape(image)[2], dimensions[0] ** 2) is True:\n",
    "        return None\n",
    "    pool_list = []\n",
    "    for pool_dim in dimensions:\n",
    "        pool_list += max_pool_2d_nxn_regions(image, pool_dim)\n",
    "    return tf.concat(pool_list, axis=1)\n",
    "\n",
    "def max_pool_2d_nxn_regions(inputs, output_size):\n",
    "    inputs_shape = tf.shape(inputs)\n",
    "    h = tf.cast(tf.gather(inputs_shape, 1), tf.int32)\n",
    "    w = tf.cast(tf.gather(inputs_shape, 2), tf.int32)\n",
    "\n",
    "    result = []\n",
    "    n = output_size\n",
    "    for row in range(output_size):\n",
    "        for col in range(output_size):\n",
    "            # start_h = floor(row / n * h)\n",
    "            start_h = tf.cast(tf.floor(tf.multiply(row / n, tf.cast(h, tf.float32))), tf.int32)\n",
    "            # end_h = ceil((row + 1) / n * h)\n",
    "            end_h = tf.cast(tf.ceil(tf.multiply((row + 1) / n, tf.cast(h, tf.float32))), tf.int32)\n",
    "            # start_w = floor(col / n * w)\n",
    "            start_w = tf.cast(tf.floor(tf.multiply(col / n, tf.cast(w, tf.float32))), tf.int32)\n",
    "            # end_w = ceil((col + 1) / n * w)\n",
    "            end_w = tf.cast(tf.ceil(tf.multiply((col + 1) / n, tf.cast(w, tf.float32))), tf.int32)\n",
    "            pooling_region = inputs[:, start_h:end_h, start_w:end_w, :]\n",
    "            pool_result = tf.reduce_max(pooling_region, axis=(1, 2))\n",
    "            result.append(pool_result)\n",
    "    return result\n",
    "\n",
    "\n",
    "TEST_LOGITS_COLLECTION_BCONV = 'TEST_LOGITS_COLLECTION_BCONV'\n",
    "TEST_LOGITS_COLLECTION = 'TEST_LOGITS_COLLECTION'\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    image_placeholders = []\n",
    "    label_placeholders = []\n",
    "\n",
    "    with tf.variable_scope(\"network\") as scope:\n",
    "        conv_reuse = None\n",
    "        for i in range(BATCH_SIZE):\n",
    "            # todo: we can add transparent images \n",
    "            image = tf.placeholder(tf.float32, shape=(1,None,None,3), name='image_{}'.format(i))\n",
    "            image_placeholders.append(image)\n",
    "            label = tf.placeholder(tf.int64, shape=(), name='label_{}'.format(i))\n",
    "            label_placeholders.append(label)\n",
    "\n",
    "            logit = tf.to_float(image)\n",
    "            logit = (logit - IMAGES_MEAN) / IMAGES_STD\n",
    "#             tf.add_to_collection(TEST_LOGITS_COLLECTION_BCONV, tf.identity(logit, name='{}_{}'.format(TEST_LOGITS_COLLECTION_BCONV, i)))\n",
    "            logit = tf.layers.conv2d(logit, 15, [1, 1], padding='SAME', reuse=conv_reuse, name='conv-1')\n",
    "            logit = tf.layers.conv2d(logit, 25, [4, 4], padding='SAME', reuse=conv_reuse, name='conv-2')\n",
    "            logit = tf.contrib.layers.max_pool2d(inputs=logit, kernel_size=[2, 2], stride=2, scope='pool-1')\n",
    "            logit = tf.layers.conv2d(logit, 15, [2, 2], padding='SAME', reuse=conv_reuse, name='conv-3')\n",
    "\n",
    "            conv_reuse = True\n",
    "#             tf.add_to_collection(TEST_LOGITS_COLLECTION, tf.identity(logit, name='{}_{}'.format(TEST_LOGITS_COLLECTION, i)))\n",
    "            logit = spp_layer(logit)\n",
    "\n",
    "            if not logit is None:\n",
    "                logit = tf.reshape(logit, [-1])\n",
    "                tf.add_to_collection(LOGITS_COLLECTION, tf.identity(logit, name='coll_logit_{}'.format(i)))\n",
    "                tf.add_to_collection(LOGIT_LABELS_COLLECTION, tf.identity(label, name='coll_label_{}'.format(i)))\n",
    "\n",
    "            scope.reuse_variables()\n",
    "        \n",
    "#     logits_TEST_BCONV = tf.get_collection(TEST_LOGITS_COLLECTION_BCONV)\n",
    "#     logits_TEST = tf.get_collection(TEST_LOGITS_COLLECTION)\n",
    "    \n",
    "    logits = tf.stack(tf.get_collection(LOGITS_COLLECTION))\n",
    "    logit_labels = tf.stack(tf.get_collection(LOGIT_LABELS_COLLECTION))\n",
    "    print(logits.shape)\n",
    "\n",
    "    logits = tf.contrib.layers.fully_connected(logits, NUM_CLASSES, activation_fn=None, scope=\"fc-2\")\n",
    "\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=logit_labels)) + 1e-6 * tf.losses.get_regularization_loss()\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        opt = tf.train.MomentumOptimizer(0.001, 0.9).minimize(loss)\n",
    "    correct = tf.equal(tf.argmax(logits, -1), logit_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    [print(v.name) for v in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)]\n",
    "    print('Number of trainable variables: {}'.format(len(tf.trainable_variables())))\n",
    "    print('Total number of variables used {}'.format(np.sum([v.get_shape().num_elements() for v in tf.trainable_variables()])))\n",
    "    \n",
    "sess = tf.Session(graph=graph)\n",
    "LOG_DIR = 'log/{}'.format(RUN_PREFIX)\n",
    "with graph.as_default(), sess.as_default():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('ready to test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to test\n",
      "[  0] Accuracy: 0.061  \t  Loss: 2.995  \t  validation accuracy: 0.080\n",
      "[  1] Accuracy: 0.078  \t  Loss: 2.891  \t  validation accuracy: 0.096\n",
      "[  2] Accuracy: 0.152  \t  Loss: 2.811  \t  validation accuracy: 0.088\n",
      "[  3] Accuracy: 0.164  \t  Loss: 2.741  \t  validation accuracy: 0.144\n",
      "[  4] Accuracy: 0.185  \t  Loss: 2.660  \t  validation accuracy: 0.128\n",
      "[  5] Accuracy: 0.215  \t  Loss: 2.589  \t  validation accuracy: 0.112\n",
      "[  6] Accuracy: 0.242  \t  Loss: 2.515  \t  validation accuracy: 0.152\n",
      "[  7] Accuracy: 0.259  \t  Loss: 2.453  \t  validation accuracy: 0.160\n",
      "[  8] Accuracy: 0.293  \t  Loss: 2.399  \t  validation accuracy: 0.160\n",
      "[  9] Accuracy: 0.299  \t  Loss: 2.345  \t  validation accuracy: 0.152\n",
      "[ 10] Accuracy: 0.349  \t  Loss: 2.258  \t  validation accuracy: 0.192\n",
      "[ 11] Accuracy: 0.358  \t  Loss: 2.173  \t  validation accuracy: 0.208\n",
      "[ 12] Accuracy: 0.387  \t  Loss: 2.097  \t  validation accuracy: 0.200\n",
      "[ 13] Accuracy: 0.402  \t  Loss: 2.022  \t  validation accuracy: 0.240\n",
      "[ 14] Accuracy: 0.423  \t  Loss: 1.950  \t  validation accuracy: 0.232\n",
      "[ 15] Accuracy: 0.425  \t  Loss: 1.885  \t  validation accuracy: 0.280\n",
      "[ 16] Accuracy: 0.465  \t  Loss: 1.773  \t  validation accuracy: 0.248\n",
      "[ 17] Accuracy: 0.507  \t  Loss: 1.704  \t  validation accuracy: 0.240\n",
      "[ 18] Accuracy: 0.505  \t  Loss: 1.628  \t  validation accuracy: 0.280\n",
      "[ 19] Accuracy: 0.547  \t  Loss: 1.525  \t  validation accuracy: 0.304\n",
      "[ 20] Accuracy: 0.575  \t  Loss: 1.452  \t  validation accuracy: 0.280\n",
      "[ 21] Accuracy: 0.589  \t  Loss: 1.381  \t  validation accuracy: 0.296\n",
      "[ 22] Accuracy: 0.602  \t  Loss: 1.283  \t  validation accuracy: 0.288\n",
      "[ 23] Accuracy: 0.596  \t  Loss: 1.257  \t  validation accuracy: 0.312\n",
      "[ 24] Accuracy: 0.638  \t  Loss: 1.211  \t  validation accuracy: 0.288\n",
      "[ 25] Accuracy: 0.636  \t  Loss: 1.171  \t  validation accuracy: 0.320\n",
      "[ 26] Accuracy: 0.667  \t  Loss: 1.110  \t  validation accuracy: 0.272\n",
      "[ 27] Accuracy: 0.691  \t  Loss: 1.043  \t  validation accuracy: 0.328\n",
      "[ 28] Accuracy: 0.678  \t  Loss: 1.008  \t  validation accuracy: 0.304\n",
      "[ 29] Accuracy: 0.699  \t  Loss: 0.985  \t  validation accuracy: 0.280\n",
      "[ 30] Accuracy: 0.720  \t  Loss: 0.930  \t  validation accuracy: 0.288\n",
      "[ 31] Accuracy: 0.697  \t  Loss: 0.922  \t  validation accuracy: 0.312\n",
      "[ 32] Accuracy: 0.758  \t  Loss: 0.861  \t  validation accuracy: 0.320\n"
     ]
    }
   ],
   "source": [
    "####################################### PART THREE #######################################\n",
    "print('starting to test')\n",
    "with graph.as_default(), sess.as_default():\n",
    "#     writer = tf.summary.FileWriter(LOG_DIR)\n",
    "#     writer.add_graph(sess.graph)\n",
    "    for epoch in range(EPOCHS):\n",
    "        np.random.seed(epoch)\n",
    "        np.random.shuffle(images_train)\n",
    "        np.random.seed(epoch)\n",
    "        np.random.shuffle(labels_train)\n",
    "        accuracy_vals, loss_vals = [], []\n",
    "        for i in range(0, len(images_train) - BATCH_SIZE + 1, BATCH_SIZE):\n",
    "            batch_images, batch_labels = images_train[i:i + BATCH_SIZE], labels_train[i:i + BATCH_SIZE]\n",
    "        \n",
    "            # todo: this is not very good... (probably replace with 1 x 1 x 1 x 1 when I implement SPP filter, do the same for training)\n",
    "            if BATCH_SIZE - len(batch_images) > 0:\n",
    "#                 print('testing diff: %d'%(BATCH_SIZE - len(batch_images)))\n",
    "                for j in range(len(batch_images), BATCH_SIZE):\n",
    "                    batch_images.append(images_train[j - len(batch_images)])\n",
    "                    batch_labels.append(labels_train[j - len(batch_images)])\n",
    "\n",
    "            fd = {**{k: v for k, v in zip(image_placeholders, batch_images)}, **{k: v for k, v in zip(label_placeholders, batch_labels )}}\n",
    "\n",
    "            accuracy_val, loss_val, _ = sess.run([accuracy, loss, opt], feed_dict=fd)\n",
    "            accuracy_vals.append(accuracy_val)\n",
    "            loss_vals.append(loss_val)\n",
    "            \n",
    "#             if i >= BATCH_SIZE * 3:\n",
    "#                 o_logits, o_logits_TEST, o_logits_TEST_BCONV = sess.run([logits, logits_TEST, logits_TEST_BCONV], feed_dict=fd)\n",
    "#                 print('[{}:{}] LOGIT LEN: {} ACC: {} LOSS: {}'.format(epoch, i, len(o_logits), accuracy_val, loss_val))\n",
    "#                 print(o_logits_TEST_BCONV[0])\n",
    "#                 print('[{}:{}] ==========================='.format(epoch, i))\n",
    "#                 print(o_logits_TEST[0])\n",
    "        val_correct = []\n",
    "        for i in range(0, len(images_val), BATCH_SIZE):\n",
    "            batch_images, batch_labels = images_val[i:i + BATCH_SIZE], labels_val[i:i + BATCH_SIZE]\n",
    "            \n",
    "            if BATCH_SIZE - len(batch_images) > 0:\n",
    "#                 print('training diff: %d'%(BATCH_SIZE - len(batch_images)))\n",
    "                for j in range(len(batch_images), BATCH_SIZE):\n",
    "                    batch_images.append(images_val[j - len(batch_images)])\n",
    "                    batch_labels.append(labels_val[j - len(batch_images)])\n",
    "                \n",
    "            fd = {**{k: v for k, v in zip(image_placeholders, batch_images)}, **{k: v for k, v in zip(label_placeholders, batch_labels )}}\n",
    "            c = sess.run(correct, feed_dict=fd)\n",
    "            val_correct.extend(c)\n",
    "\n",
    "        # s = tf.Summary()\n",
    "        # s.value.add(simple_value=np.mean(accuracy_vals), tag=\"accuracy\")\n",
    "        # s.value.add(simple_value=np.mean(loss_vals), tag=\"loss\")\n",
    "        # s.value.add(simple_value=np.mean(val_correct), tag=\"correct\")\n",
    "        # writer.add_summary(s, epoch)\n",
    "        # writer.flush()\n",
    "        # saver.save(sess, path.join(RUN_PREFIX, 'network.ckpt'), global_step=epoch)\n",
    "        print('[%3d] Accuracy: %0.3f  \\t  Loss: %0.3f  \\t  validation accuracy: %0.3f'%(epoch, np.mean(accuracy_vals), np.mean(loss_vals), np.mean(val_correct)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_val, label_val = load('tux_val.dat')\n",
    "\n",
    "print('Input shape: ' + str(image_val.shape))\n",
    "print('Labels shape: ' + str(label_val.shape))\n",
    "\n",
    "val_correct = []\n",
    "for i in range(0, image_val.shape[0], BS):\n",
    "    batch_images, batch_labels = image_val[i:i+BS], label_val[i:i+BS]\n",
    "    val_correct.extend( sess.run(correct, feed_dict={eval_inputs: batch_images, labels: batch_labels}) )\n",
    "print(\"ConvNet Validation Accuracy: \", np.mean(val_correct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.save('birds-{}.tfg'.format(RUN_PREFIX), session=sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}